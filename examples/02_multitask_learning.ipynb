{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf9caa29",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4462846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Import MirrorMind\n",
    "try:\n",
    "    from airbornehrs import AdaptiveFramework, AdaptiveFrameworkConfig\n",
    "except ImportError:\n",
    "    print(\"Installing airbornehrs...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"-e\", \"..\"])\n",
    "    from airbornehrs import AdaptiveFramework, AdaptiveFrameworkConfig\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d565f09",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41df534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load digits dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.FloatTensor(X_scaled)\n",
    "y_tensor = torch.LongTensor(y)\n",
    "\n",
    "# Define tasks by digit ranges\n",
    "tasks = {\n",
    "    \"Task 1 (0-3)\": (0, 4, [0, 1, 2, 3]),\n",
    "    \"Task 2 (4-6)\": (4, 7, [4, 5, 6]),\n",
    "    \"Task 3 (7-9)\": (7, 10, [7, 8, 9])\n",
    "}\n",
    "\n",
    "# Create task datasets\n",
    "task_datasets = {}\n",
    "for task_name, (start, end, classes) in tasks.items():\n",
    "    mask = (y >= start) & (y < end)\n",
    "    X_task = X_tensor[mask]\n",
    "    y_task = y_tensor[mask]\n",
    "    \n",
    "    # Remap labels to 0, 1, 2, ...\n",
    "    class_map = {c: i for i, c in enumerate(classes)}\n",
    "    y_task_remapped = torch.tensor([class_map[c.item()] for c in y_task])\n",
    "    \n",
    "    task_datasets[task_name] = {\n",
    "        'X': X_task,\n",
    "        'y': y_task_remapped,\n",
    "        'num_classes': len(classes),\n",
    "        'original_classes': classes\n",
    "    }\n",
    "    \n",
    "    print(f\"✓ {task_name}: {X_task.shape[0]} samples, {len(classes)} classes\")\n",
    "\n",
    "print(f\"\\n✓ Data preparation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a16a76",
   "metadata": {},
   "source": [
    "## 3. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6cbefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskNet(nn.Module):\n",
    "    \"\"\"Network for multi-task learning with shared base and task-specific heads.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=64, hidden_dim=128, num_tasks=3):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_tasks = num_tasks\n",
    "        \n",
    "        # Shared feature extraction layers\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, 64)\n",
    "        )\n",
    "        \n",
    "        # Task-specific heads\n",
    "        self.task_heads = nn.ModuleDict()\n",
    "        self.task_heads['Task 1 (0-3)'] = nn.Linear(64, 4)\n",
    "        self.task_heads['Task 2 (4-6)'] = nn.Linear(64, 3)\n",
    "        self.task_heads['Task 3 (7-9)'] = nn.Linear(64, 3)\n",
    "    \n",
    "    def forward(self, x, task_name=None):\n",
    "        features = self.shared(x)\n",
    "        \n",
    "        if task_name is None:\n",
    "            # Return all task outputs for analysis\n",
    "            return {task: head(features) for task, head in self.task_heads.items()}\n",
    "        \n",
    "        return self.task_heads[task_name](features)\n",
    "\n",
    "print(\"✓ MultiTaskNet model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ac112",
   "metadata": {},
   "source": [
    "## 4. Baseline: Vanilla PyTorch (Shows Catastrophic Forgetting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aebb12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vanilla_multitask():\n",
    "    \"\"\"Train with vanilla PyTorch, showing catastrophic forgetting.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VANILLA PYTORCH: Multi-Task Learning\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    model = MultiTaskNet(input_dim=64, hidden_dim=128)\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    results = defaultdict(lambda: {'train': [], 'task_scores': {}})\n",
    "    \n",
    "    task_order = ['Task 1 (0-3)', 'Task 2 (4-6)', 'Task 3 (7-9)']\n",
    "    \n",
    "    # Train on each task sequentially\n",
    "    for task_idx, task_name in enumerate(task_order):\n",
    "        print(f\"\\nTraining on {task_name}...\")\n",
    "        \n",
    "        X_task = task_datasets[task_name]['X']\n",
    "        y_task = task_datasets[task_name]['y']\n",
    "        \n",
    "        # Train for 15 epochs\n",
    "        for epoch in range(15):\n",
    "            indices = torch.randperm(len(X_task))\n",
    "            for i in range(0, len(X_task), 32):  # batch size 32\n",
    "                batch_idx = indices[i:i+32]\n",
    "                X_batch = X_task[batch_idx]\n",
    "                y_batch = y_task[batch_idx]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = model(X_batch, task_name)\n",
    "                loss = criterion(output, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Evaluate on ALL tasks after training current task\n",
    "        print(f\"\\nEvaluating after {task_name}...\")\n",
    "        model.eval()\n",
    "        \n",
    "        for eval_task in task_order:\n",
    "            X_eval = task_datasets[eval_task]['X']\n",
    "            y_eval = task_datasets[eval_task]['y']\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(X_eval, eval_task)\n",
    "                predictions = output.argmax(dim=1)\n",
    "                accuracy = (predictions == y_eval).float().mean().item()\n",
    "            \n",
    "            results[eval_task]['task_scores'][task_idx] = accuracy\n",
    "            print(f\"  {eval_task}: {accuracy:.1%}\")\n",
    "        \n",
    "        model.train()\n",
    "    \n",
    "    return model, results\n",
    "\n",
    "vanilla_model, vanilla_results = train_vanilla_multitask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2fa5c3",
   "metadata": {},
   "source": [
    "## 5. MirrorMind: Multi-Task Learning with EWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aee5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mirrorming_multitask():\n",
    "    \"\"\"Train with MirrorMind, preventing catastrophic forgetting.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MIRRORMING: Multi-Task Learning with EWC\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    model = MultiTaskNet(input_dim=64, hidden_dim=128)\n",
    "    \n",
    "    config = AdaptiveFrameworkConfig(\n",
    "        learning_rate=0.001,\n",
    "        meta_learning_rate=0.0001,\n",
    "        memory_type='ewc',\n",
    "        consolidation_criterion='time',\n",
    "        device='cpu',\n",
    "        enable_consciousness=True\n",
    "    )\n",
    "    \n",
    "    framework = AdaptiveFramework(model, config, device='cpu')\n",
    "    framework.train()\n",
    "    \n",
    "    results = defaultdict(lambda: {'train': [], 'task_scores': {}})\n",
    "    task_order = ['Task 1 (0-3)', 'Task 2 (4-6)', 'Task 3 (7-9)']\n",
    "    \n",
    "    # Train on each task sequentially\n",
    "    for task_idx, task_name in enumerate(task_order):\n",
    "        print(f\"\\nTraining on {task_name}...\")\n",
    "        \n",
    "        X_task = task_datasets[task_name]['X']\n",
    "        y_task = task_datasets[task_name]['y']\n",
    "        \n",
    "        # Train for 15 epochs\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        for epoch in range(15):\n",
    "            indices = torch.randperm(len(X_task))\n",
    "            for i in range(0, len(X_task), 32):\n",
    "                batch_idx = indices[i:i+32]\n",
    "                X_batch = X_task[batch_idx]\n",
    "                y_batch = y_task[batch_idx]\n",
    "                \n",
    "                output = framework.model(X_batch, task_name)\n",
    "                loss = criterion(output, y_batch)\n",
    "                \n",
    "                framework.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                framework.optimizer.step()\n",
    "                \n",
    "                # Add to feedback buffer for potential replay\n",
    "                if hasattr(framework, 'feedback_buffer'):\n",
    "                    framework.feedback_buffer.add(\n",
    "                        X_batch, output.detach(), y_batch, \n",
    "                        reward=1.0, loss=loss.item()\n",
    "                    )\n",
    "        \n",
    "        # Consolidate memory after each task\n",
    "        print(f\"Consolidating memory after {task_name}...\")\n",
    "        if hasattr(framework, 'ewc') and framework.ewc is not None:\n",
    "            # Compute Fisher information on this task\n",
    "            X_sample = X_task[:100]  # Sample for Fisher\n",
    "            y_sample = y_task[:100]\n",
    "            \n",
    "            with torch.enable_grad():\n",
    "                output_sample = framework.model(X_sample, task_name)\n",
    "                loss_sample = criterion(output_sample, y_sample)\n",
    "                loss_sample.backward()\n",
    "            \n",
    "            # Store Fisher information\n",
    "            if hasattr(framework.ewc, 'compute_fisher_on_dataset'):\n",
    "                framework.ewc.compute_fisher_on_dataset(\n",
    "                    framework.model, X_sample, y_sample, task_name\n",
    "                )\n",
    "        \n",
    ",\n",
    "\\nEvaluating after {task_name}...\")\n",
    "        framework.eval()\n",
    "        \n",
    "        for eval_task in task_order:\n",
    "            X_eval = task_datasets[eval_task]['X']\n",
    "            y_eval = task_datasets[eval_task]['y']\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = framework.model(X_eval, eval_task)\n",
    "                predictions = output.argmax(dim=1)\n",
    "                accuracy = (predictions == y_eval).float().mean().item()\n",
    "            \n",
    "            results[eval_task]['task_scores'][task_idx] = accuracy\n",
    "            print(f\"  {eval_task}: {accuracy:.1%}\")\n",
    "        \n",
    "        framework.train()\n",
    "    \n",
    "    return framework, results\n",
    "\n",
    "mirror_framework, mirror_results = train_mirrorming_multitask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7328942",
   "metadata": {},
   "source": [
    "## 6. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4759e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON: Vanilla vs MirrorMind\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "task_names = ['Task 1 (0-3)', 'Task 2 (4-6)', 'Task 3 (7-9)']\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison = {}\n",
    "for task in task_names:\n",
    "    vanilla_acc_start = vanilla_results[task]['task_scores'].get(0, 0.0)\n",
    "    vanilla_acc_final = vanilla_results[task]['task_scores'].get(2, 0.0)\n",
    "    \n",
    "    mirror_acc_start = mirror_results[task]['task_scores'].get(0, 0.0)\n",
    "    mirror_acc_final = mirror_results[task]['task_scores'].get(2, 0.0)\n",
    "    \n",
    "    vanilla_forgetting = vanilla_acc_start - vanilla_acc_final\n",
    "    mirror_forgetting = mirror_acc_start - mirror_acc_final\n",
    "    \n",
    "    print(f\"\\n{task}\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"  Vanilla:\")\n",
    "    print(f\"    Initial accuracy: {vanilla_acc_start:.1%}\")\n",
    "    print(f\"    Final accuracy:   {vanilla_acc_final:.1%}\")\n",
    "    print(f\"    Forgetting:       {vanilla_forgetting:.1%}\")\n",
    "    print(f\"  MirrorMind:\")\n",
    "    print(f\"    Initial accuracy: {mirror_acc_start:.1%}\")\n",
    "    print(f\"    Final accuracy:   {mirror_acc_final:.1%}\")\n",
    "    print(f\"    Forgetting:       {mirror_forgetting:.1%}\")\n",
    "    \n",
    "    if vanilla_forgetting > 0:\n",
    "        improvement = (vanilla_forgetting - mirror_forgetting) / vanilla_forgetting * 100\n",
    "        print(f\"  Improvement:      {improvement:.0f}% reduction in forgetting\")\n",
    "    \n",
    "    comparison[task] = {\n",
    "        'vanilla_forgetting': vanilla_forgetting,\n",
    "        'mirror_forgetting': mirror_forgetting\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a911cf7",
   "metadata": {},
   "source": [
    "## 7. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c6c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, task in enumerate(task_names):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    vanilla_scores = [vanilla_results[task]['task_scores'].get(i, 0) for i in range(3)]\n",
    "    mirror_scores = [mirror_results[task]['task_scores'].get(i, 0) for i in range(3)]\n",
    "    \n",
    "    x = np.arange(3)\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, vanilla_scores, width, label='Vanilla', alpha=0.8, color='red')\n",
    "    ax.bar(x + width/2, mirror_scores, width, label='MirrorMind', alpha=0.8, color='green')\n",
    "    \n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('After Training on Task')\n",
    "    ax.set_title(task)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(['Task 1', 'Task 2', 'Task 3'])\n",
    "    ax.set_ylim([0, 1.0])\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (v, m) in enumerate(zip(vanilla_scores, mirror_scores)):\n",
    "        ax.text(i - width/2, v + 0.02, f'{v:.0%}', ha='center', va='bottom', fontsize=9)\n",
    "        ax.text(i + width/2, m + 0.02, f'{m:.0%}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.suptitle('Multi-Task Learning: Catastrophic Forgetting Comparison', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('mirrorming_multitask_results.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Visualization saved to mirrorming_multitask_results.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a01cd3",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b3d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary metrics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "vanilla_total_forgetting = sum(c['vanilla_forgetting'] for c in comparison.values())\n",
    "mirror_total_forgetting = sum(c['mirror_forgetting'] for c in comparison.values())\n",
    "\n",
    "print(f\"\\nTotal Catastrophic Forgetting (across all tasks):\")\n",
    "print(f\"  Vanilla PyTorch: {vanilla_total_forgetting:.1%}\")\n",
    "print(f\"  MirrorMind:      {mirror_total_forgetting:.1%}\")\n",
    "\n",
    "if vanilla_total_forgetting > 0:\n",
    "    overall_improvement = (vanilla_total_forgetting - mirror_total_forgetting) / vanilla_total_forgetting * 100\n",
    "    print(f\"  Improvement:    {overall_improvement:.0f}% reduction\")\n",
    "\n",
    "print(\"\\n✓ Multi-task learning demonstration complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
