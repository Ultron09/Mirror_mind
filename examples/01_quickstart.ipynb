{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55b2012",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries\n",
    "\n",
    "First, let's import what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f254afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import MirrorMind\n",
    "from airbornehrs import AdaptiveFramework, AdaptiveFrameworkConfig\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9feefa9",
   "metadata": {},
   "source": [
    "## Step 1: Define the Model\n",
    "\n",
    "A simple 3-layer neural network for digit classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562487c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    \"\"\"Simple feedforward network for digit classification.\"\"\"\n",
    "    def __init__(self, input_dim=64, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNet()\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d5a9b0",
   "metadata": {},
   "source": [
    "## Step 2: Load and Prepare Data\n",
    "\n",
    "We'll use scikit-learn's digit dataset (8x8 images of digits 0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load digits dataset\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to tensors\n",
    "X = torch.FloatTensor(X)\n",
    "y = torch.LongTensor(y)\n",
    "\n",
    "# Split: Task 1 (digits 0-4) and Task 2 (digits 5-9)\n",
    "task1_mask = y < 5\n",
    "task2_mask = y >= 5\n",
    "\n",
    "X_task1, y_task1 = X[task1_mask], y[task1_mask]\n",
    "X_task2, y_task2 = X[task2_mask], (y[task2_mask] - 5)  # Relabel 5-9 as 0-4\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader_1 = DataLoader(TensorDataset(X_task1, y_task1), batch_size=batch_size, shuffle=True)\n",
    "train_loader_2 = DataLoader(TensorDataset(X_task2, y_task2), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"Task 1: {len(X_task1)} samples (digits 0-4)\")\n",
    "print(f\"Task 2: {len(X_task2)} samples (digits 5-9)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03634d4c",
   "metadata": {},
   "source": [
    "## Step 3: Vanilla PyTorch - Show Catastrophic Forgetting\n",
    "\n",
    "Train a normal model on Task 1, then Task 2. Watch the first task accuracy drop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e903dab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, device='cpu'):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = F.cross_entropy(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device='cpu'):\n",
    "    \"\"\"Evaluate accuracy.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            logits = model(X_batch)\n",
    "            pred = logits.argmax(dim=1)\n",
    "            correct += (pred == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "    return correct / total\n",
    "\n",
    "# Train vanilla model (no EWC)\n",
    "vanilla_model = SimpleNet()\n",
    "vanilla_opt = torch.optim.Adam(vanilla_model.parameters(), lr=1e-3)\n",
    "\n",
    "print(\"\\n=== VANILLA (No Memory Protection) ===\")\n",
    "print(\"\\nTask 1 Training...\")\n",
    "for epoch in range(10):\n",
    "    loss = train_epoch(vanilla_model, train_loader_1, vanilla_opt)\n",
    "\n",
    "task1_acc_before = evaluate(vanilla_model, train_loader_1)\n",
    "print(f\"Task 1 Accuracy: {task1_acc_before:.1%}\")\n",
    "\n",
    "print(\"\\nTask 2 Training (forgetting Task 1)...")\n",
    "for epoch in range(10):\n",
    "    loss = train_epoch(vanilla_model, train_loader_2, vanilla_opt)\n",
    "\n",
    "task1_acc_after = evaluate(vanilla_model, train_loader_1)\n",
    "task2_acc = evaluate(vanilla_model, train_loader_2)\n",
    "\n",
    "print(f\"Task 1 Accuracy (after Task 2): {task1_acc_after:.1%}  <-- CATASTROPHIC FORGETTING!\")\n",
    "print(f\"Task 2 Accuracy: {task2_acc:.1%}\")\n",
    "forgetting_rate = (task1_acc_before - task1_acc_after) * 100\n",
    "print(f\"\\nAccuracy drop on Task 1: {forgetting_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3681ddc",
   "metadata": {},
   "source": [
    "## Step 4: MirrorMind - Prevent Catastrophic Forgetting\n",
    "\n",
    "Now use MirrorMind's `AdaptiveFramework`. Watch the forgetting drop significantly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc73455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MirrorMind model (with EWC)\n",
    "mm_model = SimpleNet()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Configure MirrorMind\n",
    "config = AdaptiveFrameworkConfig(\n",
    "    learning_rate=1e-3,\n",
    "    memory_type='hybrid',  # Use EWC + SI for protection\n",
    "    consolidation_criterion='surprise',  # Consolidate when something new is seen\n",
    "    enable_consciousness=False,  # Keep simple for this demo\n",
    "    use_prioritized_replay=False,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Wrap the model in the framework\n",
    "framework = AdaptiveFramework(mm_model, config=config)\n",
    "# The framework automatically moves the model to the correct device.\n",
    "\n",
    "print(\"\\n=== MIRRORMIND (With Memory Protection) ===\")\n",
    "print(\"\\nTask 1 Training...\")\n",
    "\n",
    "# --- Train on Task 1 --- \n",
    "for epoch in range(10):\n",
    "    for x_batch, y_batch in train_loader_1:\n",
    "        x_batch, y_batch = x_batch.to(framework.device), y_batch.to(framework.device)\n",
    "        # train_step handles everything automatically\n",
    "        metrics = framework.train_step(x_batch, target_data=y_batch)\n",
    "\n",
    "task1_acc_before_mm = evaluate(framework.model, train_loader_1, device=framework.device)\n",
    "print(f\"Task 1 Accuracy: {task1_acc_before_mm:.1%}\")\n",
    "\n",
    "# --- Consolidate Memory --- \n",
    "# Manually trigger consolidation after finishing a task.\n",
    "# This tells the framework to calculate and lock the importance of weights for Task 1.\n",
    "print(\"\\nConsolidating memory from Task 1...\")\n",
    "framework.memory.consolidate(feedback_buffer=framework.feedback_buffer)\n",
    "print(\"Memory consolidated (Importance weights locked)\")\n",
    "\n",
    "print(\"\\nTask 2 Training (Memory protection is active)...")\n",
    "\n",
    "# --- Train on Task 2 --- \n",
    "for epoch in range(10):\n",
    "    for x_batch, y_batch in train_loader_2:\n",
    "        x_batch, y_batch = x_batch.to(framework.device), y_batch.to(framework.device)\n",
    "        # The memory penalty is now automatically applied during this train_step\n",
    "        metrics = framework.train_step(x_batch, target_data=y_batch)\n",
    "\n",
    "# --- Evaluate --- \n",
    "task1_acc_after_mm = evaluate(framework.model, train_loader_1, device=framework.device)\n",
    "task2_acc_mm = evaluate(framework.model, train_loader_2, device=framework.device)\n",
    "\n",
    "print(f\"Task 1 Accuracy (after Task 2): {task1_acc_after_mm:.1%}  <-- PROTECTION SUCCESSFUL!\")\n",
    "print(f\"Task 2 Accuracy: {task2_acc_mm:.1%}\")\n",
    "forgetting_rate_mm = (task1_acc_before_mm - task1_acc_after_mm) * 100\n",
    "print(f\"\\nAccuracy drop on Task 1: {forgetting_rate_mm:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf3adc6",
   "metadata": {},
   "source": [
    "## Step 5: Compare Results\n",
    "\n",
    "Let's visualize the improvement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Chart 1: Task 1 Accuracy Drop\n",
    "methods = ['Vanilla\\n(No Protection)', 'MirrorMind\\n(Protected)']\n",
    "forgetting = [forgetting_rate, forgetting_rate_mm]\n",
    "colors = ['#d62728', '#2ca02c']  # Red for bad, green for good\n",
    "\n",
    "axes[0].bar(methods, forgetting, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "axes[0].set_ylabel('Accuracy Drop on Task 1 (%)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Catastrophic Forgetting Comparison', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylim(0, max(forgetting_rate, forgetting_rate_mm) * 1.2 + 5)\n",
    "for i, v in enumerate(forgetting):\n",
    "    axes[0].text(i, v + 1, f'{v:.1f}%', ha='center', fontsize=11, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Chart 2: Task Accuracies\n",
    "x = np.arange(2)\n",
    "width = 0.35\n",
    "\n",
    "task1_before = [task1_acc_before, task1_acc_before_mm]\n",
    "task1_after = [task1_acc_after, task1_acc_after_mm]\n",
    "\n",
    "bars1 = axes[1].bar(x - width/2, task1_before, width, label='Task 1 (Before Task 2)', color='#1f77b4', alpha=0.7, edgecolor='black')\n",
    "bars2 = axes[1].bar(x + width/2, task1_after, width, label='Task 1 (After Task 2)', color='#ff7f0e', alpha=0.7, edgecolor='black')\n",
    "\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Task 1 Accuracy Before & After Task 2', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(methods)\n",
    "axes[1].set_ylim(0, 1.1)\n",
    "axes[1].legend(loc='lower left')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mirrormind_quickstart_results.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nChart saved as 'mirrormind_quickstart_results.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cd8723",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the core value of the MirrorMind framework: its ability to mitigate catastrophic forgetting in a continual learning setting. By using a memory protection mechanism (like EWC or SI), the framework preserves knowledge from previously learned tasks while adapting to new ones.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore other examples to see more advanced features like the `ConsciousnessCore`.\n",
    "- Read the `README.md` and `docs/` for detailed architectural and API documentation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}