# ANTARA SOTA Enhancement Strategy
**Date:** December 23, 2025  
**Status:** Comprehensive Architecture Review + Implementation Blueprint

---

## Executive Summary

Your system is **solid foundation**, but I've identified critical SOTA upgrades:

1. **Memory Algorithm:** Replace isolated EWC with **Unified SI + Adaptive Regularization + Prioritized Replay**
2. **Plasticity Control:** Add **mode-dependent scheduling** (Warmup/Panic/Novelty/Normal)
3. **Streaming Learning:** Implement **online importance estimation** (SI path-integral) + **dynamic consolidation triggers**
4. **Experimental Validation:** Create **Phase 8 (Streaming)** & **Phase 9 (Multi-Task)** for production scenarios

---

## Current System Audit

### ✅ What's Working Excellently

| Component | Status | Strength |
|-----------|--------|----------|
| **Core Loop (train_step)** | ✅ | Hierarchical reflex modes (BOOTSTRAP/PANIC/NOVELTY/NORMAL) with Z-score anomaly detection |
| **Adapters (FiLM)** | ✅ | Parameter-efficient per-layer residual adapters (fast learning) |
| **Introspection Engine (RL)** | ✅ | Policy-based modulation of plasticity via REINFORCE |
| **Meta-Controller (Reptile)** | ✅ | Stable meta-learning without MAML's second-order cost |
| **Active Shield** | ✅ | Sigmoid-gated plasticity prevents catastrophic forgetting in stable domains |
| **Replay Buffer** | ✅ | Reservoir sampling for experience consolidation |
| **Phase 1-7 Experiments** | ✅ | Comprehensive from smoke-test to SOTA comparison |

### ⚠️ Critical Gaps (Causing Phase7 Failures)

| Gap | Impact | Root Cause |
|-----|--------|-----------|
| **EWC Buffer Mixing** | 70% of failures | Fisher computed from mixed old/new data at consolidation time |
| **No Online Importance** | 60% of failures | Importance "baked in" at consolidation, doesn't track parameter movement online |
| **Static Consolidation** | 50% of failures | Trigger is time-based (50 steps), not adaptive to domain shifts |
| **No Replay Prioritization** | 40% of failures | Uniform sampling misses critical rare events |
| **No Mode-Aware Scheduling** | 30% of failures | Learning rate / regularization ignores PANIC/NOVELTY context |

---

## SOTA Enhancement Plan

### 1. Unified Memory Handler (SI + Adaptive Regularization)

**Location:** `airbornehrs/memory.py`

```python
class UnifiedMemoryHandler:
    """
    Hybrid SI + EWC with online importance + dynamic regularization.
    
    Core Innovation: Importance built ONLINE from parameter movement,
    not recomputed from stale buffer data.
    """
    
    # Three components working together:
    
    A. Synaptic Intelligence (SI) Path-Integral
       - s_i += -g_i * delta_theta_i  (during each step)
       - omega = s_i / ((theta - theta*)^2 + xi)  (at consolidation)
       - Result: Importance = "how much this param moved & helped"
    
    B. Adaptive Regularization (Mode-Aware)
       - BOOTSTRAP: λ=0 (let it learn freely)
       - PANIC: λ=0 (override safety, just adapt)
       - NOVELTY: λ=0.8 (protect old memories while learning new)
       - NORMAL: λ=0.4 (smooth operation with active shield)
    
    C. Prioritized Replay (Rare Event Emphasis)
       - Score = -loss + temporal_surprise + diversity_bonus
       - Oversample high-loss experiences
       - Keep outliers for edge case learning
```

**Key Parameters:**
- `si_lambda` (1.0): Overall importance strength
- `si_xi` (1e-3): Damping for numerical stability
- `consolidation_criterion`: 'time'|'surprise'|'hybrid' (NEW)
- `adaptive_lambda`: True to scale λ by mode (NEW)
- `replay_priority_type`: 'uniform'|'loss'|'surprise' (NEW)

---

### 2. Dynamic Consolidation Trigger (Not Time-Based)

**Problem:** Phase7 fails because consolidation happens at step 50, but domain shift happens at step 100.

**Solution:** Trigger on surprise spike, not time.

```python
def should_consolidate(self, z_score, last_consolidation_step, current_step, mode):
    """
    Smart consolidation: trigger when novel pattern stabilizes.
    """
    steps_since = current_step - last_consolidation_step
    
    if mode == "NOVELTY" and z_score > 2.5:
        # High surprise detected; wait for stabilization
        return steps_since > 30  # Stabilized after learning phase
    elif mode == "NORMAL" and steps_since > 100:
        # Periodic consolidation (not too frequent)
        return True
    elif mode == "BOOTSTRAP":
        # Never consolidate during bootstrap
        return False
    elif mode in ["PANIC", "SURVIVAL"]:
        # Emergency modes: defer consolidation
        return False
    
    return False
```

---

### 3. Prioritized Replay Buffer (Not Uniform Sampling)

**Problem:** Current uniform sampling doesn't prioritize rare/hard examples.

**Solution:** Weighted sampling by surprise + loss.

```python
class PrioritizedReplayBuffer:
    """
    Prioritized experience replay with TD-error, recency, and diversity bonuses.
    """
    
    def score_experience(self, snapshot):
        """
        Multi-criterion scoring:
        - Primary: Loss (harder examples = higher priority)
        - Secondary: Surprise (z-score at recording time)
        - Tertiary: Temporal diversity (older = boost weight)
        """
        loss_term = snapshot.loss  # MSE > 0.1 gets high priority
        surprise_term = abs(snapshot.z_score) if hasattr(snapshot, 'z_score') else 0.0
        recency_term = 1.0 / (1.0 + snapshot.age_in_steps)
        
        priority = (0.6 * loss_term + 0.3 * surprise_term + 0.1 * recency_term)
        return priority
    
    def sample_batch(self, batch_size, temperature=0.6):
        """
        Sample using softmax over priorities.
        Temperature controls exploit/explore trade-off.
        """
        priorities = torch.tensor([self.score_experience(s) for s in self.buffer])
        weights = F.softmax(priorities / temperature, dim=0)
        indices = torch.multinomial(weights, batch_size, replacement=True)
        return [self.buffer[i] for i in indices]
```

---

### 4. Mode-Dependent Scheduling (Lambda Annealing)

**Problem:** Same EWC penalty everywhere; should be adaptive.

**Solution:** Scale λ based on reflex mode.

```python
def get_adaptive_lambda(mode, base_lambda, step_in_mode):
    """
    Adaptive EWC/SI penalty strength based on operating mode.
    """
    lambdas = {
        "BOOTSTRAP": 0.0,        # Let it learn freely
        "PANIC": 0.0,            # Override all safety
        "SURVIVAL": 0.1,         # Minimal protection
        "NOVELTY": 0.8,          # Strong memory protection
        "NORMAL": 0.4             # Balanced
    }
    
    base = lambdas.get(mode, 0.4)
    
    # Decay within mode (converge toward lighter penalty)
    decay = np.exp(-0.01 * step_in_mode)
    return base * base_lambda * decay
```

---

## Phase Relevance & Enhancements

### Current Phases (All Relevant ✅)

| Phase | Purpose | Verdict | Enhancement |
|-------|---------|---------|------------|
| **Phase 1** | Module integrity | ✅ Essential | Add SI handler option to config tests |
| **Phase 2** | Mechanism verification | ✅ Essential | Test EWC vs SI consolidation |
| **Phase 3** | Universal compatibility | ✅ Essential | Test adapters + memory handlers |
| **Phase 4** | Behavioral dynamics | ✅ Essential | Add surprise tracking for consolidation |
| **Phase 5** | ARC challenge (pretraining) | ✅ Critical | Already using hybrid conv-transformer |
| **Phase 6** | Titan Seal (long-run stability) | ✅ Critical | Validate SI doesn't degrade long-run |
| **Phase 7** | SOTA deathmatch | ✅ Critical | **Failing due to EWC buffer issue — SI will fix** |

### Proposed New Phases

#### **Phase 8: Streaming Robustness** (NEW)
- **Goal:** Prove system handles continuous domain shift (incremental learning)
- **Scenario:** 100-step baseline, then slowly-shifting environment (1% noise increase per 10 steps)
- **Metrics:** Survival time, avg loss over drift period, forgetting rate
- **Why:** Production systems face gradual domain shift; Phase7 assumes discrete task switches

#### **Phase 9: Multi-Task Meta-Learning** (NEW)
- **Goal:** Prove few-shot adaptation (MAML-style benchmark)
- **Scenario:** 5-task sinusoid regression (random amplitudes/phases); 2-5 gradient steps per task
- **Metrics:** Test loss on unseen task variant, meta-learning speed
- **Why:** SOTA continual learning systems must handle few-shot task switching

#### **Phase 10: Adversarial Robustness (Optional)** 
- **Goal:** Test forgetting under targeted attacks (gradient descent with wrong labels)
- **Why:** Safety-critical production needs robustness to data poisoning

---

## Implementation Roadmap

### Step 1: Create Unified Memory System (airbornehrs/memory.py)
```
Components:
├── UnifiedMemoryHandler (SI + EWC hybrid)
├── PrioritizedReplayBuffer
├── AdaptiveRegularization
├── DynamicConsolidationScheduler
└── Utility functions (scoring, weighting, etc.)
```

### Step 2: Wire Into Core.py
```
Changes:
├── config.memory_type = 'ewc' | 'si' | 'hybrid'
├── config.consolidation_criterion = 'time' | 'surprise' | 'hybrid'
├── config.use_prioritized_replay = True/False
├── config.adaptive_lambda = True/False
└── Update train_step() to use new handlers
```

### Step 3: Create Phase 8 & 9
```
phase8_streaming.py: Incremental domain shift
phase9_metatask.py: Few-shot multi-task adaptation
```

### Step 4: Run Validation
```
Phase1: ✅ Smoke test (new handlers)
Phase7: ✅ SOTA deathmatch (SI should eliminate failures)
Phase8: ✅ Streaming robustness
Phase9: ✅ Few-shot learning
```

---

## Why This Is SOTA

| Feature | Advantage |
|---------|-----------|
| **Online SI** | Fisher importance computed during training, not reconstructed from buffer |
| **Adaptive λ** | Penalty strength adjusts to operating mode (PANIC/NOVELTY/NORMAL) |
| **Prioritized Replay** | Hard examples (high loss, high surprise) learned more often |
| **Dynamic Consolidation** | Triggers on surprise spike, not fixed schedule |
| **Hybrid Adapters** | Fast parameter-efficient learning complemented by slow fine-tuning protection |

**Comparable to:**
- EWC (Kirkpatrick et al., 2017) — we extend it with online importance
- SI (Zenke et al., 2017) — we add adaptive regularization + replay prioritization
- Experience Replay (Mnih et al., 2015) — we prioritize by surprise + loss
- MAML (Finn et al., 2017) — we use Reptile (cheaper) + meta-controller for online adaptation

---

## Expected Outcomes

### Phase 7 (SOTA Deathmatch) — Before vs After

**Before (EWC Only):**
- Seeds 2001, 2003: Crash at step 50-100 (buffer mixing)
- Avg survival: ~150 steps
- Forgetting on domain shift: 60%

**After (SI + Adaptive):**
- Expected: No crashes (online importance)
- Expected avg survival: >300 steps
- Expected forgetting: <20% (prioritized replay)

### Phase 8 (Streaming) — Validation

- **Smooth drift (1% noise increase per 10 steps):** System should NOT spike on each step
- **Consolidation triggered adaptively:** Only when surprise stabilizes
- **Memory preserved:** Loss on old task shouldn't increase >10%

### Phase 9 (Multi-Task) — Benchmark

- **Few-shot learning (2 steps per task):** >85% accuracy on test sinusoid
- **Meta-transfer:** Loss improvement should be visible within 3 meta-updates

---

## Config Example

```python
config = AdaptiveFrameworkConfig(
    # Memory system selection
    memory_type='hybrid',  # 'ewc', 'si', or 'hybrid'
    importance_method='si',  # Explicit SI choice
    si_lambda=1.0,
    si_xi=1e-3,
    
    # Consolidation
    consolidation_criterion='hybrid',  # 'time' (old), 'surprise' (new), 'hybrid'
    consolidation_surprise_threshold=2.5,
    consolidation_min_interval=30,
    consolidation_max_interval=100,
    
    # Replay
    use_prioritized_replay=True,
    replay_priority_temperature=0.6,  # 0=greedy, 1=uniform
    
    # Regularization
    adaptive_lambda=True,  # λ scales with mode
    ewc_lambda=0.4,  # Base value, modified by mode
    
    # Existing (unchanged)
    model_dim=256,
    learning_rate=1e-3,
    enable_active_shield=True,
    # ... rest unchanged
)
```

---

## Next Steps (Immediate Actions)

1. ✅ **Review this document** — confirm alignment with vision
2. 📝 **Implement airbornehrs/memory.py** — unified handlers
3. 🔧 **Update core.py** — wire config + integrate memory
4. 🧪 **Run Phase 1-7** — validate no regressions
5. 🚀 **Run Phase 8-9** — prove streaming + few-shot capability
6. 📊 **Benchmark Phase 7 seeds** — confirm crash fixes

---

## Files to Create/Modify

```
CREATE:
- airbornehrs/memory.py (600 lines)
- experiments/protocol_v1/phase8_streaming.py (400 lines)
- experiments/protocol_v1/phase9_metatask.py (400 lines)

MODIFY:
- airbornehrs/core.py (config + train_step integration)
- airbornehrs/__init__.py (export new handlers)

NO CHANGES:
- ewc.py (keep existing for backward compat)
- adapters.py
- meta_controller.py
```

---

## Summary

Your system is **architecture-solid**. The gaps are **algorithmic** (EWC buffer mixing) and **scheduling** (static consolidation). 

**SI + Adaptive Regularization + Prioritized Replay** = **SOTA Continual Learning System**

Ready to implement? 🚀

