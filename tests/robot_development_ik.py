"""
ANTARA Robot Development: Inverse Kinematics
=============================================
Simulates a robot learning to control its body (Inverse Kinematics)
through "Motor Babbling" across developmental stages.

Task: Learn mapping f: Target(x,y,z) -> JointAngles(q1,q2,q3)
Training: Supervised learning on (angles, pos) pairs generated by the robot itself.
Why interesting?
- Domain Incremental Learning: The domain of targets expands over time.
- Coherent Function: The physics doesn't change, but the active workspace does.
- Dreaming Value: Replaying old "zones" ensures global mastery.

STAGES:
1. TUMMY TIME: Limited range, mostly shoulder.
2. CRAWLING: Wider XY range, low Z.
3. STANDING: High Z, limited XY.
4. WALKING: Full workspace exploration.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
from airbornehrs.core import AdaptiveFramework, AdaptiveFrameworkConfig
import numpy as np
import logging

logging.disable(logging.CRITICAL)
torch.manual_seed(42)
np.random.seed(42)

# ============ ROBOT KINEMATICS ============
class RobotArm:
    def __init__(self):
        self.link_lengths = [1.0, 0.8, 0.5]
    
    def forward_kinematics(self, angles):
        """Compute end-effector pos from angles (batch supported)."""
        # angles: [batch, 3]
        if isinstance(angles, np.ndarray):
            angles = torch.FloatTensor(angles)
        
        batch_size = angles.shape[0] if len(angles.shape) > 1 else 1
        if len(angles.shape) == 1:
            angles = angles.unsqueeze(0)
            
        x = torch.zeros(batch_size)
        y = torch.zeros(batch_size)
        cumulative_angle = torch.zeros(batch_size)
        
        for i in range(3):
            cumulative_angle += angles[:, i]
            x += self.link_lengths[i] * torch.cos(cumulative_angle)
            y += self.link_lengths[i] * torch.sin(cumulative_angle)
            
        # Z depends on 3rd joint for 3D effect
        z = 0.5 * torch.sin(angles[:, 1] + angles[:, 2]) # Simplified 3D
        
        return torch.stack([x, y, z], dim=1)

    def generate_babbling_data(self, stage, n_samples=1000):
        """
        Generate (pos, angles) pairs for a specific developmental stage.
        Babbling is restricted angle ranges.
        """
        angles = torch.zeros(n_samples, 3)
        
        if stage == 'tummy_time':
            # Stage 1: Mostly shoulder (q0), small movements
            angles[:, 0] = torch.rand(n_samples) * 1.0  # 0 to 1 rad
            angles[:, 1] = torch.rand(n_samples) * 0.2  # stiff elbow
            angles[:, 2] = torch.rand(n_samples) * 0.2  # stiff wrist
            
        elif stage == 'crawling':
            # Stage 2: Shoulder + Elbow, Low Z
            angles[:, 0] = torch.rand(n_samples) * 3.14  # full shoulder
            angles[:, 1] = torch.rand(n_samples) * 1.5   # half elbow
            angles[:, 2] = torch.rand(n_samples) * 0.5   # stiff wrist
            
        elif stage == 'standing':
            # Stage 3: High reaching (shoulder up, elbow up)
            angles[:, 0] = torch.rand(n_samples) * 2.0 + 1.0 # high shoulder
            angles[:, 1] = torch.rand(n_samples) * 2.0
            angles[:, 2] = torch.rand(n_samples) * 1.0
            
        elif stage == 'walking':
            # Stage 4: Full random exploration
            angles[:, 0] = torch.rand(n_samples) * 6.28 - 3.14
            angles[:, 1] = torch.rand(n_samples) * 3.14 - 1.57
            angles[:, 2] = torch.rand(n_samples) * 3.14 - 1.57
            
        pos = self.forward_kinematics(angles)
        return pos, angles

# ============ MODEL (Inverse Kinematics) ============
def create_ik_model():
    """Predicts 3 angles from 3D pos."""
    return nn.Sequential(
        nn.Linear(3, 128), nn.ReLU(),
        nn.Linear(128, 128), nn.ReLU(),
        nn.Linear(128, 3)
    )

class NaiveIK(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = create_ik_model()
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)
    
    def train_step(self, x, y):
        self.optimizer.zero_grad()
        pred = self.model(x)
        loss = F.mse_loss(pred, y)
        loss.backward()
        self.optimizer.step()
        return loss.item()
        
    def forward(self, x):
        return self.model(x)

# ============ EXPERIMENT ============
def run_ik_development(agent, name, robot):
    print(f"   Running: {name}...", end=" ", flush=True)
    
    stages = ['tummy_time', 'crawling', 'standing', 'walking']
    history = []
    
    for stage_idx, stage in enumerate(stages):
        # 1. Generate Babbling Data
        train_pos, train_angles = robot.generate_babbling_data(stage, n_samples=2000)
        
        # 2. Train
        batch_size = 32
        for _ in range(500): # steps
            idx = torch.randint(0, len(train_pos), (batch_size,))
            x = train_pos[idx]
            y = train_angles[idx]
            
            if isinstance(agent, AdaptiveFramework):
                agent.train_step(x, target_data=y)
            else:
                agent.train_step(x, y)
                
            # Stream consolidation
            if isinstance(agent, AdaptiveFramework) and agent.prioritized_buffer:
                 # Check buffer size safely
                 buffer_size = len(agent.prioritized_buffer.buffer)
                 if buffer_size > 100 and _ % 100 == 0:
                     try:
                        agent.memory.consolidate(agent.prioritized_buffer, current_step=agent.step_count, mode='NORMAL')
                     except: pass
        
        # 3. Evaluate on ALL stages (Retention Test)
        stage_acc = []
        with torch.no_grad():
            for test_stage in stages:
                test_pos, test_angles = robot.generate_babbling_data(test_stage, n_samples=100)
                
                if isinstance(agent, AdaptiveFramework):
                    output = agent(test_pos)
                    pred_angles = output[0] if isinstance(output, tuple) else output
                else:
                    pred_angles = agent(test_pos)
                
                # Metric: Position Error (Forward Kinematics of pred angles vs target pos)
                pred_pos = robot.forward_kinematics(pred_angles)
                error = torch.norm(pred_pos - test_pos, dim=1).mean().item()
                stage_acc.append(error)
        
        history.append(stage_acc)
        
    print("Done")
    return np.array(history)

# ============ MAIN ============
def run_simulation():
    print("\n" + "="*70)
    print("ðŸ¤– ROBOT DEVELOPMENT: INVERSE KINEMATICS")
    print("="*70)
    print("Learning Body Control through Motor Babbling")
    print("Stages: Tummy Time â†’ Crawling â†’ Standing â†’ Walking")
    print("Metric: Reaching Error (Lower is better)\n")
    
    robot = RobotArm()
    results = {}
    
    # 1. Naive (Forgetful)
    print("ðŸ”¬ [1/3] Naive Baseline...")
    naive = NaiveIK()
    results['Naive'] = run_ik_development(naive, "Naive", robot)
    
    # 2. ANTARA Minimal (EWC)
    print("ðŸ”¬ [2/3] ANTARA Minimal (EWC)...")
    cfg_min = AdaptiveFrameworkConfig(
        device='cpu',
        memory_type='ewc',
        ewc_lambda=500.0,
        enable_dreaming=False,
        compile_model=False,
    )
    min_agent = AdaptiveFramework(create_ik_model(), cfg_min, device='cpu')
    results['ANTARA-Min'] = run_ik_development(min_agent, "ANTARA-Min", robot)
    
    # 3. ANTARA + Dreaming
    print("ðŸ”¬ [3/3] ANTARA + Dreaming...")
    cfg_dream = AdaptiveFrameworkConfig(
        device='cpu',
        memory_type='hybrid',
        ewc_lambda=100.0,
        enable_dreaming=True,
        dream_interval=20,
        dream_batch_size=32,
        use_prioritized_replay=True,
        compile_model=False,
    )
    dream_agent = AdaptiveFramework(create_ik_model(), cfg_dream, device='cpu')
    results['ANTARA+Dream'] = run_ik_development(dream_agent, "ANTARA+Dream", robot)
    
    return results

def plot_results(results, filename):
    stages = ['Tummy', 'Crawl', 'Stand', 'Walk']
    
    # Plot 1: Average Error over time
    plt.figure(figsize=(10, 6))
    for name, history in results.items():
        # history is [4, 4] matrix (current_stage, test_stage)
        # We want average error on ALL stages after each stage
        avg_errors = history.mean(axis=1)
        plt.plot(avg_errors, marker='o', label=name, linewidth=2)
        
    plt.xticks(range(4), stages)
    plt.xlabel("Developmental Stage")
    plt.ylabel("Avg Reaching Error (Lower is Better)")
    plt.title("Robot Skill Acquisition & Retention")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig(filename, dpi=150)
    plt.close()
    
    # Print Matrix
    print("\nFINAL ERROR MATRIX (Rows: Trained Stage, Cols: Test Stage)")
    for name, history in results.items():
        print(f"\n{name}:")
        print("      " + " ".join([f"{s:>7}" for s in stages]))
        for i, row in enumerate(history):
            print(f"{stages[i]:<5} " + " ".join([f"{val:.4f}" for val in row]))

if __name__ == "__main__":
    results = run_simulation()
    plot_results(results, "tests/robot_ik_results.png")
    print("\nâœ¨ SIMULATION COMPLETE")
